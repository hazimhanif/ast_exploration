{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the AST structure from file generated by CodeSensor-Minimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### return list of that \n",
    "\n",
    "def get_AST(count_level):\n",
    "    \n",
    "    if count_level == 0:\n",
    "        return(out[0])\n",
    "    \n",
    "    if count_level == 1:\n",
    "        return(out[0][1:])\n",
    "    \n",
    "    if count_level == 2:\n",
    "        temp = []\n",
    "        for ls1 in out[0][1:]:\n",
    "            for ls2 in ls1[1:]:\n",
    "                temp.append(ls2)\n",
    "        return(temp)\n",
    "        \n",
    "    \n",
    "    if count_level == 3:\n",
    "        temp = []\n",
    "        for ls1 in out[0][1:]:\n",
    "            for ls2 in ls1[1:]:\n",
    "                for ls3 in ls2[1:]:\n",
    "                    temp.append(ls3)\n",
    "        return(temp)\n",
    "    \n",
    "    if count_level == 4:\n",
    "        temp = []\n",
    "        for ls1 in out[0][1:]:\n",
    "            for ls2 in ls1[1:]:\n",
    "                for ls3 in ls2[1:]:\n",
    "                    for ls4 in ls3[1:]:\n",
    "                        temp.append(ls4)\n",
    "        return(temp)\n",
    "    \n",
    "    if count_level == 5:\n",
    "        temp = []\n",
    "        for ls1 in out[0][1:]:\n",
    "            for ls2 in ls1[1:]:\n",
    "                for ls3 in ls2[1:]:\n",
    "                    for ls4 in ls3[1:]:\n",
    "                        for ls5 in ls4[1:]:\n",
    "                            temp.append(ls5)\n",
    "        return(temp)\n",
    "    \n",
    "    if count_level == 6:\n",
    "        temp = []\n",
    "        for ls1 in out[0][1:]:\n",
    "            for ls2 in ls1[1:]:\n",
    "                for ls3 in ls2[1:]:\n",
    "                    for ls4 in ls3[1:]:\n",
    "                        for ls5 in ls4[1:]:\n",
    "                            for ls6 in ls5[1:]:\n",
    "                                temp.append(ls6)\n",
    "        return(temp)\n",
    "    \n",
    "    if count_level == 7:\n",
    "        temp = []\n",
    "        for ls1 in out[0][1:]:\n",
    "            for ls2 in ls1[1:]:\n",
    "                for ls3 in ls2[1:]:\n",
    "                    for ls4 in ls3[1:]:\n",
    "                        for ls5 in ls4[1:]:\n",
    "                            for ls6 in ls5[1:]:\n",
    "                                for ls7 in ls6[1:]:\n",
    "                                    temp.append(ls7)\n",
    "        return(temp)\n",
    "    \n",
    "    if count_level == 8:\n",
    "        temp = []\n",
    "        for ls1 in out[0][1:]:\n",
    "            for ls2 in ls1[1:]:\n",
    "                for ls3 in ls2[1:]:\n",
    "                    for ls4 in ls3[1:]:\n",
    "                        for ls5 in ls4[1:]:\n",
    "                            for ls6 in ls5[1:]:\n",
    "                                for ls7 in ls6[1:]:\n",
    "                                    for ls8 in ls7[1:]:\n",
    "                                        temp.append(ls8)\n",
    "        return(temp)\n",
    "    \n",
    "    if count_level == 9:\n",
    "        temp = []\n",
    "        for ls1 in out[0][1:]:\n",
    "            for ls2 in ls1[1:]:\n",
    "                for ls3 in ls2[1:]:\n",
    "                    for ls4 in ls3[1:]:\n",
    "                        for ls5 in ls4[1:]:\n",
    "                            for ls6 in ls5[1:]:\n",
    "                                for ls7 in ls6[1:]:\n",
    "                                    for ls8 in ls7[1:]:\n",
    "                                        for ls9 in ls8[1:]:\n",
    "                                            temp.append(ls9)\n",
    "        return(temp)\n",
    "    \n",
    "    if count_level == 10:\n",
    "        temp = []\n",
    "        for ls1 in out[0][1:]:\n",
    "            for ls2 in ls1[1:]:\n",
    "                for ls3 in ls2[1:]:\n",
    "                    for ls4 in ls3[1:]:\n",
    "                        for ls5 in ls4[1:]:\n",
    "                            for ls6 in ls5[1:]:\n",
    "                                for ls7 in ls6[1:]:\n",
    "                                    for ls8 in ls7[1:]:\n",
    "                                        for ls9 in ls8[1:]:\n",
    "                                            for ls10 in ls9[1:]:\n",
    "                                                temp.append(ls10)\n",
    "        return(temp)\n",
    "    \n",
    "    if count_level == 11:\n",
    "        temp = []\n",
    "        for ls1 in out[0][1:]:\n",
    "            for ls2 in ls1[1:]:\n",
    "                for ls3 in ls2[1:]:\n",
    "                    for ls4 in ls3[1:]:\n",
    "                        for ls5 in ls4[1:]:\n",
    "                            for ls6 in ls5[1:]:\n",
    "                                for ls7 in ls6[1:]:\n",
    "                                    for ls8 in ls7[1:]:\n",
    "                                        for ls9 in ls8[1:]:\n",
    "                                            for ls10 in ls9[1:]:\n",
    "                                                for ls11 in ls10[1:]:\n",
    "                                                    temp.append(ls11)\n",
    "        return(temp)\n",
    "    \n",
    "    if count_level == 12:\n",
    "        temp = []\n",
    "        for ls1 in out[0][1:]:\n",
    "            for ls2 in ls1[1:]:\n",
    "                for ls3 in ls2[1:]:\n",
    "                    for ls4 in ls3[1:]:\n",
    "                        for ls5 in ls4[1:]:\n",
    "                            for ls6 in ls5[1:]:\n",
    "                                for ls7 in ls6[1:]:\n",
    "                                    for ls8 in ls7[1:]:\n",
    "                                        for ls9 in ls8[1:]:\n",
    "                                            for ls10 in ls9[1:]:\n",
    "                                                for ls11 in ls10[1:]:\n",
    "                                                    for ls12 in ls11[1:]:\n",
    "                                                        temp.append(ls12)\n",
    "        return(temp)\n",
    "    \n",
    "    if count_level == 13:\n",
    "        temp = []\n",
    "        for ls1 in out[0][1:]:\n",
    "            for ls2 in ls1[1:]:\n",
    "                for ls3 in ls2[1:]:\n",
    "                    for ls4 in ls3[1:]:\n",
    "                        for ls5 in ls4[1:]:\n",
    "                            for ls6 in ls5[1:]:\n",
    "                                for ls7 in ls6[1:]:\n",
    "                                    for ls8 in ls7[1:]:\n",
    "                                        for ls9 in ls8[1:]:\n",
    "                                            for ls10 in ls9[1:]:\n",
    "                                                for ls11 in ls10[1:]:\n",
    "                                                    for ls12 in ls11[1:]:\n",
    "                                                        for ls13 in ls12[1:]:\n",
    "                                                            temp.append(ls13)\n",
    "        return(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual translation from 2 files (True & False - Training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 507810424718792183281259521741240442631433370359504668250336"
     ]
    }
   ],
   "source": [
    "## True\n",
    "\n",
    "import ast\n",
    "reader = open('output/train_true.txt','r')\n",
    "length = len(reader.readlines())\n",
    "reader = open('output/train_true.txt','r')\n",
    "all_func_from_file = []\n",
    "doc_count = 0\n",
    "for i in range(0,length):\n",
    "    \n",
    "    try:\n",
    "        all_stmt = ast.literal_eval(reader.readline()[:-1])\n",
    "        all_lvl  = ast.literal_eval(reader.readline()[:-1])\n",
    "        \n",
    "        final_func = []\n",
    "        for i in range(len(all_stmt)):\n",
    "            stmt = all_stmt[i]\n",
    "            lvl = all_lvl[i]\n",
    "\n",
    "            out = [[]]\n",
    "            count_level = -1\n",
    "            curr = []\n",
    "            full = True\n",
    "\n",
    "            for i in range(0,len(lvl)):\n",
    "\n",
    "                if i == 0:\n",
    "                    # level 0\n",
    "                    out[0].append(stmt[0])\n",
    "                else:\n",
    "                    if lvl[i]!=lvl[i-1]:\n",
    "                        count_level +=1\n",
    "                        curr = get_AST(count_level)\n",
    "\n",
    "                        if count_level ==0:\n",
    "                            curr.append([stmt[i]])\n",
    "                        else:\n",
    "                            curr[0].append([stmt[i]])\n",
    "\n",
    "                    else:\n",
    "                        if count_level ==0:\n",
    "                            curr.append([stmt[i]])\n",
    "                        else:\n",
    "                            full = True\n",
    "                            for j in range(0,len(curr)):\n",
    "                                if len(curr[j])<3:\n",
    "                                    curr[j].append([stmt[i]])\n",
    "                                    full = False\n",
    "                                    break\n",
    "\n",
    "                            if full == True:\n",
    "                                for j in range(0,len(curr)):\n",
    "                                    if len(curr[j])<4:\n",
    "                                        curr[j].append([stmt[i]])\n",
    "                                        break\n",
    "            final_func.append(out[0])\n",
    "        final_func.append(['}'])\n",
    "        all_func_from_file.append(final_func)\n",
    "        print('\\r',doc_count,end='')\n",
    "        doc_count += 1\n",
    "    except:\n",
    "        all_lvl = reader.readline()\n",
    "        next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## True\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "true_df = pd.DataFrame(range(0,len(all_func_from_file)), columns=['id'])\n",
    "true_df['code'] = all_func_from_file\n",
    "true_df['label'] = np.repeat(1,len(all_func_from_file)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 171863296949951613142139631679116817"
     ]
    }
   ],
   "source": [
    "## False\n",
    "\n",
    "import ast\n",
    "reader = open('output/train_false.txt','r')\n",
    "length = len(reader.readlines())\n",
    "reader = open('output/train_false.txt','r')\n",
    "all_func_from_file = []\n",
    "doc_count = 0\n",
    "for i in range(0,length):\n",
    "    \n",
    "    try:\n",
    "        all_stmt = ast.literal_eval(reader.readline()[:-1])\n",
    "        all_lvl  = ast.literal_eval(reader.readline()[:-1])\n",
    "        \n",
    "        final_func = []\n",
    "        for i in range(len(all_stmt)):\n",
    "            stmt = all_stmt[i]\n",
    "            lvl = all_lvl[i]\n",
    "\n",
    "            out = [[]]\n",
    "            count_level = -1\n",
    "            curr = []\n",
    "            full = True\n",
    "\n",
    "            for i in range(0,len(lvl)):\n",
    "\n",
    "                if i == 0:\n",
    "                    # level 0\n",
    "                    out[0].append(stmt[0])\n",
    "                else:\n",
    "                    if lvl[i]!=lvl[i-1]:\n",
    "                        count_level +=1\n",
    "                        curr = get_AST(count_level)\n",
    "\n",
    "                        if count_level ==0:\n",
    "                            curr.append([stmt[i]])\n",
    "                        else:\n",
    "                            curr[0].append([stmt[i]])\n",
    "\n",
    "                    else:\n",
    "                        if count_level ==0:\n",
    "                            curr.append([stmt[i]])\n",
    "                        else:\n",
    "                            full = True\n",
    "                            for j in range(0,len(curr)):\n",
    "                                if len(curr[j])<3:\n",
    "                                    curr[j].append([stmt[i]])\n",
    "                                    full = False\n",
    "                                    break\n",
    "\n",
    "                            if full == True:\n",
    "                                for j in range(0,len(curr)):\n",
    "                                    if len(curr[j])<4:\n",
    "                                        curr[j].append([stmt[i]])\n",
    "                                        break\n",
    "            final_func.append(out[0])\n",
    "        final_func.append(['}'])\n",
    "        all_func_from_file.append(final_func)\n",
    "        print('\\r',doc_count,end='')\n",
    "        doc_count += 1\n",
    "        if doc_count == 600000:\n",
    "        #    break\n",
    "            doc_count=0\n",
    "            all_func_from_file = []\n",
    "    except:\n",
    "        all_lvl = reader.readline()\n",
    "        next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## False\n",
    "\n",
    "false_df = pd.DataFrame(range(0,len(all_func_from_file)), columns=['id'])\n",
    "false_df['code'] = all_func_from_file\n",
    "false_df['label'] = np.repeat(0,len(all_func_from_file)).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine TRUE & FALSE and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save\n",
    "final_df = true_df.append(false_df,ignore_index=True)\n",
    "final_df.to_pickle('output/train.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load train data\n",
    "import pandas as pd\n",
    "train = pd.read_pickle('output/train.pickle')\n",
    "train = train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to flat the nested list\n",
    "def flatten(x):\n",
    "    return(list(pd.core.common.flatten(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = train.code.apply(flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make sure every token is in string type\n",
    "for line in corpus:\n",
    "    for j in range(0,len(line)):\n",
    "        if type(line[j]) == int:\n",
    "            line[j] = str(line[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the Word2Vec model\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "w2v = Word2Vec(corpus, size=128, workers=16, sg=1, min_count=3)\n",
    "w2v.save('output/node_w2v_128')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert token to index using trained Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "w2v = Word2Vec.load('output/node_w2v_128')\n",
    "\n",
    "def recurse(node):\n",
    "    for i in range(0,len(node)):\n",
    "        if type(node[i]) == str:\n",
    "            node[i] = w2v.wv.vocab.get(node[i]).index if node[i] in w2v.wv.vocab else w2v.wv.vectors.shape[0]-1\n",
    "        elif type(node[i]) == list:\n",
    "            recurse(node[i])\n",
    "        else:\n",
    "            node[i] = w2v.wv.vocab.get(str(node[i])).index if str(node[i]) in w2v.wv.vocab else w2v.wv.vectors.shape[0]-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mydf = pd.read_pickle('output/train.pickle')\n",
    "mydf.code.apply(recurse)\n",
    "mydf = mydf.sample(frac=1, random_state=666)\n",
    "mydf.to_pickle('output/train_final.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
