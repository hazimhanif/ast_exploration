{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the AST structure from file generated by CodeSensor-Complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual translation from 2 files (True & False - Training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRUE\n",
    "\n",
    "import ast\n",
    "k = open('myCS/output/train_true.txt','r')\n",
    "length = len(k.readlines())\n",
    "k = open('myCS/output/train_true.txt','r')\n",
    "all1 = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRUE\n",
    "\n",
    "for i in range(0,length):\n",
    "    try:\n",
    "        all1.append(ast.literal_eval(k.readline()[:-1]))\n",
    "        print('\\r',i,end='')\n",
    "    except:\n",
    "        next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRUE\n",
    "\n",
    "true_df = pd.DataFrame(list(range(0,len(all1))), columns=['id'])\n",
    "true_df['code'] = all1\n",
    "true_df['label'] = np.repeat(0,len(all1)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FALSE\n",
    "\n",
    "import ast\n",
    "k = open('myCS/output/train_false.txt','r')\n",
    "length = len(k.readlines())\n",
    "k = open('myCS/output/train_false.txt','r')\n",
    "all2 = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FALSE\n",
    "\n",
    "for i in range(0,length):\n",
    "    try:\n",
    "        all2.append(ast.literal_eval(k.readline()[:-1]))\n",
    "        print('\\r',i,end='')\n",
    "    except:\n",
    "        next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FALSE\n",
    "\n",
    "false_df = pd.DataFrame(list(range(0,len(all2))), columns=['id'])\n",
    "false_df['code'] = all2\n",
    "false_df['label'] = np.repeat(0,len(all2)).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine TRUE & FALSE and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save\n",
    "\n",
    "final_df = true_df.append(false_df,ignore_index=True)\n",
    "final_df.to_pickle('output/train.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load train data\n",
    "\n",
    "train = pd.read_pickle('output/train.pickle')\n",
    "train = train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to flat the nested list\n",
    "def flatten(x):\n",
    "    return(list(pd.core.common.flatten(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = train.code.apply(flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make sure every token is in string type\n",
    "for line in corpus:\n",
    "    for j in range(0,len(line)):\n",
    "        if type(line[j]) == int:\n",
    "            line[j] = str(line[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the Word2Vec model\n",
    "w2v = Word2Vec(corpus, size=128, workers=16, sg=1, min_count=3)\n",
    "w2v.save('output/node_w2v_128')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert token to index using trained Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec.load('output/node_w2v_128')\n",
    "\n",
    "def recurse(node):\n",
    "    for i in range(0,len(node)):\n",
    "        if type(node[i]) == str:\n",
    "            node[i] = w2v.wv.vocab.get(node[i]).index if node[i] in w2v.wv.vocab else w2v.wv.vectors.shape[0]-1\n",
    "        elif type(node[i]) == list:\n",
    "            recurse(node[i])\n",
    "        else:\n",
    "            node[i] = w2v.wv.vocab.get(str(node[i])).index if str(node[i]) in w2v.wv.vocab else w2v.wv.vectors.shape[0]-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = pd.read_pickle('output/train.pickle')\n",
    "mydf.code.apply(recurse)\n",
    "mydf = mydf.sample(frac=1, random_state=666)\n",
    "mydf.to_pickle('output/train_final.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
